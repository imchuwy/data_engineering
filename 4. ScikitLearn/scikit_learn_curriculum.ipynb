{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# scikit-learn mini-curriculum\n",
        "## Goals\n",
        "- Train/test split, pipelines, and transformers\n",
        "- Supervised basics: linear/logistic regression, decision trees, k-NN\n",
        "- Model evaluation: cross-val, metrics, confusion matrices/ROC\n",
        "- Feature scaling/encoding with `ColumnTransformer`\n",
        "- Hyperparameter tuning with `GridSearchCV`/`RandomizedSearchCV`\n",
        "- Persistence with `joblib` and reproducibility\n",
        "\n",
        "## Step-by-step path\n",
        "1. Setup & mindset\n",
        "   - Install scikit-learn + pandas, bookmark docs, set `random_state` habit\n",
        "   - Know when to pick classification vs regression; define target + metric upfront\n",
        "2. Data loading & splits\n",
        "   - Use `train_test_split` with `stratify` for classification; keep a holdout\n",
        "   - Basic EDA: dtypes, missingness, leakage checks, target distribution\n",
        "3. Baselines & metrics\n",
        "   - Fit `DummyClassifier`/`DummyRegressor` to set a floor; track chosen metric (`accuracy`, `F1`, `MAE`/`RMSE`)\n",
        "   - Add `classification_report`, confusion matrix, ROC/PR for class imbalance; for regression log RMSE/MAE and residual plots\n",
        "4. Preprocessing pipeline\n",
        "   - Build a `ColumnTransformer` for numeric (imputer + scaler) and categorical (imputer + `OneHotEncoder(handle_unknown=\"ignore\")`)\n",
        "   - Wrap preprocessing + model in a `Pipeline` to keep leakage-free training\n",
        "5. Core estimators\n",
        "   - Classification: logistic regression, k-NN, decision tree; note linear vs non-linear trade-offs\n",
        "   - Regression: linear regression, ridge/lasso (regularization), decision tree regressor\n",
        "6. Cross-validation & evaluation\n",
        "   - Use `cross_validate` with `scoring` dict to capture multiple metrics; prefer stratified KFold for classification\n",
        "   - Inspect variance across folds to reason about bias/variance and data sufficiency\n",
        "7. Hyperparameter tuning\n",
        "   - Set small grids for `GridSearchCV` or wider ranges for `RandomizedSearchCV`; keep pipelines in the search object\n",
        "   - Review `cv_results_` and learning/validation curves to choose simpler vs more complex models\n",
        "8. Feature engineering\n",
        "   - Try scaling-aware transforms (`StandardScaler`) before distance-based models; use `PolynomialFeatures` or interactions carefully\n",
        "   - Handle target/feature leakage; encode dates into useful parts (year, month, hour) when applicable\n",
        "9. Model diagnostics & interpretability\n",
        "   - Check feature importances/permutation importances; plot partial dependence for tree-based models\n",
        "   - Calibrate probabilities (`CalibratedClassifierCV`) when decision thresholds matter\n",
        "10. Persistence & delivery\n",
        "    - Save the final pipeline with `joblib.dump`; include preprocessing so inference matches training\n",
        "    - Log versions/seeds, freeze dependencies, and document input schema + expected metrics\n",
        "\n",
        "## Suggested exercises\n",
        "- Load a tabular dataset, split data, and build a pipeline with preprocessing + a baseline model\n",
        "- Compare two algorithms on accuracy/F1 (or RMSE/MAE) and discuss bias/variance from fold results\n",
        "- Tune a small hyperparameter grid on one model, inspect `best_params_`, and evaluate on the untouched holdout\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}